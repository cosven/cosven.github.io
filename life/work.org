* 工作

- 2017-12-27 13:55:06 工作，赚钱用的？

** 工程效率

PaaS、CI/CD、微服务、serverless

*** TODO CI 文档优化
*** TODO 推广新版本包困难
*** TODO 提高部署稳定性
*** TODO 构建系统运维自动化
*** PaaS
*** 构建 and 部署
**** 部署
***** 灰度部署 - 解决发布稳定性问题
***** 分支部署 - 解决线上测试、联调、验收等问题
**** 构建
***** lavie 改进
1. 运维有点问题，docker images 占用机器内存
2. pipeline script 写起来很恶心

*** 微服务

**** 文章 - The Death of Microservice Madness in 2018
     CLOCK: [2018-01-22 Mon 11:00]--[2018-01-22 Mon 12:00] =>  1:00
[[http://www.dwmkerr.com/the-death-of-microservice-madness-in-2018/]]

*讲了什么是微服务，微服务为什么流行？*
独立部署-独立开发-独立扩容-可复用

*为啥微服务之前没流行？*
基础设施健全了

*微服务有什么问题？*
开发复杂度-运维复杂度-devops 复杂度-需要这方面专家-实际系统之间边界模糊
-服务有状态-服务之前有数据交换-版本管理-分布式事务-

*避免盲目使用微服务*
团队大小-服务是否有状态-服务解决的问题是否是多个-依赖是否复杂-团队是否有专家

*微服务不是一种架构*
Component 化的一种实现

** 工作备忘录
*** miller 一些疑问 [1/1]
- [X] Miller 每个任务是一个线程，还是一个进程，还是什么东东？
  miller 会配合 gevent 来使用？

*** 部署改进
**** 日志方向
现在的日志是一个 process 对应一个日志
但理论上应该是一个 deploy 对应一个日志，然后日志分 process
**** 概念方向
canary -> alpha
canary2 -> beta
**** TODO 部署卡顿的问题
**** TODO bay 和 newbay 概念上的区别，流程也有区别
*** 个人反思：整理个人状态
**** 2017-12-21

*最近状态不好？不好在哪些方面？*

1. 工作效率低
2. 但是时间花费不少
3. 烦恼

效率为啥低 ->
有段时间，上午自己会研究平时遇到的问题
有段时间，花了一些在折腾 emacs 上
另外，要甩锅的地方，就是提个 MR，但是流程长。另外方案也不一样
*** 金丝雀
**** DONE 让 A/S 类业务加上金丝雀2
**** DONE 上线金丝雀修改的 MR

**** DONE 查金丝雀报警的问题并修复
     CLOSED: [2018-02-26 Mon 15:27]
     CLOCK: [2018-02-26 Mon 14:27]--[2018-02-26 Mon 15:27] =>  1:00
     CLOCK: [2018-01-25 Thu 14:08]--[2018-01-25 Thu 15:43] =>  1:35
创建报警有重复或者超时的时候，会漏记一些报警。

**** DONE 金丝雀回滚和上线冲突的问题
     CLOCK: [2018-03-19 Mon 17:43]--[2018-03-19 Mon 20:43] =>  3:00
不要既触发回滚，又触发上线。
*** 工作 tasks
**** DONE oauth 在前后端分离中的应用 [100%]
    CLOCK: [2017-12-04 Mon 22:48]--[2017-12-05 Tue 01:53] =>  3:05

- [[https://zh.wikipedia.org/wiki/%E8%B7%A8%E7%AB%99%E8%AF%B7%E6%B1%82%E4%BC%AA%E9%80%A0-][CSRF 跨站请求伪造]] -> 重要操作不要用 GET；CSRF 保护措施（cookie 和 query 参数中带 csrf_token）


***** DONE 目前例子中实现的方案
      CLOSED: [2018-01-08 Mon 18:22]
1. 访问 http://A 时，前端检测是否有 token，没有 token 就重定向到 /oauth/authorize 页面
2. 用户在 authorize 页面输入用户名和密码，如果验证成功，重定向到用户指定的 redirect_url 上。
   比如 /oauth/callback 上（这个页面是前端的一个页面）。（此时，页面是有 grant_code 的）
3. 前端用 grant_code 给后端，后端用这个 code 去 oauth 换 token。
   换取成功后，后端把这个 token 保存起来。再把 token 返回给前端，前端存起来。
4. 之后，后端每次都去校验前端传过来的 token

***** DONE 一般的实现方案 [100%]
1. 设置 cookie（有安全风险）（好像比较传统）
2. 在 localStorage 中保存

3. [X] token 方案 vs session 方案
token 提高了安全性，避免了额 CSRF 攻击
但是认为可以修改 token，万一踩狗屎了呢？

- [X] 传统 token 方案 vs JWT
jwt 是个自包含的东西，服务端不需要去查数据库来验证这个东西是否正确。
人为不方便修改 jwt。

***** DONE SSO 实现方案
思路：[[https://segmentfault.com/a/1190000005357718]]

A,B 是应用服务器。L 是认证服务器。
客户端存一个 L 分发下去的 session_id。
A 检测客户端是否有 session_id_a，没有让 L 去验证，验证完之后，设置一个 session_id_a。
B 同理。

**** DONE Performance Review
     DEADLINE: <2018-01-03 Wed>
     CLOCK: [2018-01-03 Wed 13:20]--[2018-01-03 Wed 13:52] =>  0:32

**** DONE OKR Review
     CLOSED: [2018-01-03 Wed 16:09] DEADLINE: <2018-01-03 Wed>
确认一下 OKR 细节

**** DONE 梳理机器人账号
     CLOSED: [2018-01-04 Thu 15:24]
     CLOCK: [2018-01-04 Thu 15:00]--[2018-01-04 Thu 16:30] =>  1:30
     CLOCK: [2018-01-04 Thu 11:00]--[2018-01-04 Thu 12:00] =>  1:00
ZAE-386

**** DONE [#C] 把机器人账号单独放一个组
     CLOSED: [2018-02-05 Mon 17:51]
**** DONE 计算 P95 of task reserved time
     CLOSED: [2018-01-04 Thu 21:04]
     CLOCK: [2018-01-04 Thu 17:01]--[2018-01-04 Thu 21:03] =>  4:02

percentileOfSeries 配合 gauge 使用
**** DONE 周报补一下 task 链接
     CLOSED: [2018-01-08 Mon 18:28]
**** DONE [#A] 离线任务滚动部署
     CLOSED: [2018-03-15 Thu 16:48]
    CLOCK: [2017-12-19 Tue 14:11]--[2017-12-19 Tue 19:44] =>  5:33
    CLOCK: [2017-12-19 Tue 14:09]--[2017-12-19 Tue 14:11] =>  0:02
    CLOCK: [2017-12-18 Mon 20:02]--[2017-12-18 Tue 20:30] =>  0:28
    CLOCK: [2017-12-15 Fri 17:10]--[2017-12-15 Fri 20:03] =>  2:53
    CLOCK: [2017-12-14 Thu 17:00]--[2017-12-14 Thu 22:58] =>  5:58
    CLOCK: [2017-12-13 Wed 16:52]--[2017-12-13 Web 19:00] =>  2:08
    CLOCK: [2017-12-13 Wed 14:39]--[2017-12-13 Wed 16:40] =>  2:01
    CLOCK: [2018-02-07 Wed 11:03]--[2018-02-07 Wed 19:03] =>  8:00

***** 一些基本认识（基础逻辑）

1. 一个版本的生命周期
| 没上线    | 灰度中 | 上线了  | 下线了    |
|-----------+--------+---------+-----------|
| Candidate | Canary | Releasd | Destroyed |

如果已经部署过 newbay 了
|          | percent | t<10 gc | release canary | t>10 gc |
| initial  |       0 | Y       | N/A            | Y       |
| rolling  |   0-100 | N       | Y              | N       |
| released |   0-100 | N       | N              | N       |
| obsolete |       0 | N       | N/A            | Y       |

构建 -> (Artifact) -> Candidate -> 测试环境 -> 办公室环境 -> 生产环境
DEV -> Testing -> tarball -> alpha -> beta -> RC -> Release

生产环境：-> 灰度 -> 上线。上线失败和成功

1. *假设 Alpha 对应 Canary1，Beta 对应 Canary2*
那么有三种环境：Testing/Office/Production
每个版本有几个状态：Alpha(Canary1)/Beta(Canary2)/Release(Production) - RC(正在上线的版本)

2. *canary 应该被看做百分比，而不应该看做 stage*
看做 stage 有很多麻烦... 比如:
set_stage_version('canary', 'xxx')  # 失败的设计
set_version('Production', 'xxx', percent=20)  # 成功

3. *一个 version 有多个 stage，stage 是 version 的属性*

4. 上线状态和 Stage 概念是正交，还是咋样？

一个版本需要状态有哪些： Ready -> Canary -> Releasing -> Released -> Outdated

|            | 正在上线 | 已经上线   | 已经下线 |
| production | RC       | Released   | Outdated |
| canary     | ____     | Canary     | Outdated |
| office     | ____     | office/(R) | Outdated |
| testing    | ____     | testing(R) | Outdated |

正交的缺点：
1. 有些正交结果没有意义

假设以后使用百分比：
这种情况有点问题，不能判断哪个是生产环境。（没有办法明确的表明，当前处于灰度阶段）
| v1 | PROD | 已经上线 | 20% |
| v2 | PROD | 已经上线 | 80% |

| v1 | PROD | 正在上线 | 30% |
| v2 | PROD | 已经上线 | 70%  |

假设
| v1 | PROD | Canary   | 20% |
| v2 | PROD | Released | 20% |

| v1 | PROD | Releasing | 20% |
| v2 | PROD | Released  | 80% |

***** DONE 滚动部署方案
     CLOCK: [2017-12-22 Fri 11:00]--[2017-12-22 Fri 17:34] =>  6:34

部署就是一个发布的过程。
发包的过程，熟悉吗？发布和发包过程是不是比较类似呢？
发布和代码变更过程是不是类似呢？也有点类似 Release/Canary/ReleaseCandidate

***** DONE 一个 stage 对应多个 version
      CLOSED: [2018-01-11 Thu 18:11]
1. 理论上可以
2. stage_version_map 干了啥？
3. 存在两个 production version -> 没办法判断金丝雀版本是否与生产环境版本一样，没办法回滚金丝雀
    1. 如果只有离线任务的话，就无所谓
    2. 不会滚，并进行提醒
4. 存在两个 production 版本，部署金丝雀时，不知道该缩放哪个版本
    1. 只增不减（如果只有离线任务，也不会有这个问题）

实际证明：不太可行。一个 stage 必须要有一个主版本，
扩容的时候总不能两个都扩把？（其实两个都扩也没有多大问题把）

***** DONE 实现离线任务滚动部署
      CLOSED: [2018-01-08 Mon 17:08]
***** DONE review+修改
      CLOSED: [2018-01-11 Thu 18:11]
      CLOCK: [2018-01-08 Mon 16:08]--[2018-01-08 Mon 16:48] =>  0:40

***** 讨论旧版本只 scale down
      CLOCK: [2018-02-26 Mon 11:36]--[2018-02-26 Mon 12:04] =>  0:28

***** DONE 新的滚动部署策略实现
      CLOCK: [2018-02-27 Tue 14:05]--[2018-02-27 Tue 23:00] =>  8:55

***** DONE 新版本 scale 的时候，不要超过目标值
      CLOSED: [2018-03-15 Thu 16:56]
jira:NAMI-93
**** oauth2 杂事
     CLOCK: [2018-02-26 Mon 11:22]--[2018-02-26 Mon 11:32] =>  0:10
     CLOCK: [2017-12-20 Wed 13:40]--[2017-12-20 Wed 21:09] =>  7:29
- 将 xxx 加到 cxo list 里面

***** DONE 发邮件失败
***** DONE oauth2 支持 redirect url wildcard
      CLOSED: [2017-12-28 Thu 08:56]
***** DONE 同步信息时使用批量接口
**** DONE [#B] python3.6 for jessie
     CLOSED: [2018-01-11 Thu 17:16]
     CLOCK: [2018-01-11 Thu 11:12]--[2018-01-11 Thu 15:55] =>  4:43
     CLOCK: [2018-01-10 Wed 11:12]--[2018-01-10 Wed 20:24] =>  9:12
     CLOCK: [2018-01-05 Fri 15:36]--[2018-01-05 Fri 18:30] =>  2:54
***** DONE python3.6-dev 包？
      CLOSED: [2018-01-11 Thu 15:55]
***** DONE 各种编译选项都有啥用？
      CLOSED: [2018-01-11 Thu 15:13]

- *--with-fpectl*

#+BEGIN_QUOTE
allowing the user to turn on the generation of SIGFPE whenever
any of the IEEE-754 exceptions Division by Zero, Overflow,
or Invalid Operation occurs
#+END_QUOTE

- *--enable-loadable-sqlite-extensions*
enabled in other building

- *--enable-shared*
generate libpython3.6.so in /usr/lib path, which is need for
compile other python packages

- *--with-system-ffi*
other building also enable this

- *--enable-optimizations*
https://github.com/python/cpython#id5

- *--with-dbmliborder=bdb:gdbm*
- *--with-computed-gotos*

***** DONE 搞清楚各大 python 包有什么用？
      CLOSED: [2018-01-11 Thu 15:55]
***** DONE 搞清楚官方包是怎样打的？
      CLOSED: [2018-01-11 Thu 15:55]

#+BEGIN_SRC shell
gnuArch="$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)" \
&& ./configure \
--build="$gnuArch" \
--enable-loadable-sqlite-extensions \
--enable-shared \
--enable-ipv6 \
--with-system-expat \
--with-system-ffi \
--without-ensurepip \
--enable-optimizations

make
sudo make install DESTDIR=/tmp/py3tmp

sudo fpm -s dir -t deb -n python3.6 -v 3.6.3 -C /tmp/py3tmp \
-p python3.6_VERSION_ARCH.deb \
-d libreadline-dev \
-d libffi-dev \
-d libssl-dev \
-d libexpat-dev \
-d libsqlite3-dev \
-d dpkg-dev \
-d tcl-dev \
-d tk-dev \
-x usr/local/bin/2to3
+END_SRC

*python2 和 python3 包的一些可执行文件有冲突*
fpm 指定 conflicts：可以指定和某个包冲突，提示用户卸载那个包
fpm 可以指定 exclude 某个文件 =-x= 选项

*python shell 不能使用 C-a*
预先安装 libreadline-dev 再 configure
ps: libreadline-dev 依赖了 libreadline6-dev

*PGO 编译选项*

***** DONE 尝试 backporting 官方的 Python 3 包
      CLOCK: [2018-03-13 Thu 10:00]--[2018-03-13 Thu 18:00] =>  8:00
按照 [[https://wiki.debian.org/SimpleBackportCreation][Debian backporting 教程]] 指导，尝试 backport Debian buster Python3.6。

实践会遇到两个问题：

- jessie 中 libmpdec2 版本是 2.4.1，而 Python3.6 会 Breaks << 2.4.2 的 libmpdec2，
这是一个问题，但是它是可以被解决的。libmpdec2 2.4.2 相对于 2.4.1 只有几个 bugfix，
理论上可以比较安全将 libmpdec2 也 backport 一下，实践证明确实可以比较轻松的 backporting 2.4.2。
- 第二个问题目前还没有方法可以解决。在 buster 中，Python3.6 和 Python3-distutils 是循环依赖的。
目前没有什么简单的办法可以 backport 这两个东西，可能需要一些更加专业的手段才能完成这两个包的 backporting...

**** DONE [#B] pipenv vs buildout vs ...
     CLOSED: [2018-01-25 Thu 13:48]
     CLOCK: [2018-01-23 Tue 10:59]--[2018-01-25 Thu 10:48] => 47:49
     CLOCK: [2018-01-22 Mon 13:34]--[2018-01-22 Mon 20:34] =>  7:00
     CLOCK: [2018-01-19 Fri 16:16]--[2018-01-19 Mon 20:56] =>  4:40
     CLOCK: [2018-01-16 Tue 13:00]--[2018-01-16 Tue 14:00] =>  1:00
     CLOCK: [2018-01-15 Tue 11:00]--[2018-01-15 Tue 17:38] =>  6:38

**** TODO [#A] 部署出错，确认资源方
**** DONE 容器组回收策略文档
     CLOSED: [2018-01-08 Mon 15:43]
     CLOCK: [2018-01-08 Mon 13:49]--[2018-01-08 Mon 15:43] =>  1:54
**** DONE 把 artifacts MR 后续事情搞定
**** DONE 应用级别修改限制
**** DONE nami 打指标
     CLOCK: [2018-01-16 Tue 17:07]--[2018-01-16 Tue 20:07] =>  3:00
**** MR review
***** hashring
     CLOCK: [2018-01-16 Tue 15:29]--[2018-01-16 Tue 16:29] =>  1:00
     CLOCK: [2018-01-16 Tue 12:10]--[2018-01-16 Tue 12:40] =>  0:30

***** logging
      CLOCK: [2018-01-30 Tue 10:37]--[2018-01-30 Tue 10:51] =>  0:14

**** DONE 2018-1-17 一天折腾
     CLOCK: [2018-01-17 Wed 12:30]--[2018-01-17 Wed 18:02] =>  5:32
- 讨论 nami celery
- CI 上传包出了问题
- 部署打点图表
- oncall

**** DONE 机器人账号单独分组
     CLOSED: [2018-01-19 Fri 10:47]
oauth2-5
**** DONE 大概搞懂 buildout 的原理
     CLOCK: [2018-01-19 Fri 11:26]--[2018-01-19 Fri 16:09] =>  4:43
     CLOCK: [2018-01-18 Fri 10:26]--[2018-01-18 Fri 20:26] => 10:00
基于 setuptools 重写了 easy_install

**** TODO Python __setstate__ 是干啥用的？
**** DONE [#A] app 级别的环境变量
     CLOSED: [2018-02-05 Mon 17:51]
     CLOCK: [2018-01-29 Mon 14:18]--[2018-01-29 Mon 19:58] =>  5:40
     CLOCK: [2018-01-25 Thu 15:58]--[2018-01-25 Mon 20:54] =>  4:56
**** DONE [#B] 给外包同学新建账号
     CLOSED: [2018-02-01 Thu 14:14]
我们主要要解决的问题是什么？是安全问题，还是外包同学
访问内部系统是否方便的问题？
如果是安全问题，新方案也没有解决。
如果是使用问题，现在其实也就麻烦一点？另外，具体的使用场景是什么？

1. HR 为什么不管理外包同学？
如果由 HR 来统一管理的话，就可以有一套统一的流程
我们来管的话，就需要多很多沟通
（比如他们也没有在北森系统里面存在）
2. 需不需要考虑安全问题？谁来管？
目前的状况，新建了账号之后，和之前使用一个机器人账号有什么区别

会议结论：目前主要是要解决外包同学的使用问题。另外，使用每个外包同学
使用各自的账号，出了问题，也更方便排查。其它的安全问题暂时没办法解决。

**** DONE 简单了解 redux 是个啥东西？
     CLOSED: [2018-02-01 Thu 15:19]
     CLOCK: [2018-02-01 Thu 14:19]--[2018-02-01 Thu 15:19] =>  1:00
这狗东西硬要说自己 Simple，结果文档里面到处都要人去看 Flux...

- =Actions= are payloads of information that send data from your application to your store.
- =Action creators= functions that create actions.
- =Reducers= specify how the application's state changes in response to actions sent to the store.
- =Store= 把上面几个东西结合到一起 -> 项目代码中的 @connect 就是这个东西的运用

（真的 hold 不住...）
**** DONE 协助 newbay 迁移

假设一个 unit 在 newbay 上存在 1 个版本：那么，nami 不需要管它 。

假设一个 unit 在 newbay 上存在多个版本：
这个 unit 势必是走 nami 部署过，那么，nami 知道线上是哪个版本。
这时，nami 从 bay 获取这个 unit 所有的容器组，将非线上版本干掉。
**** TODO Python3 App 示例
     CLOCK: [2018-03-05 Mon 13:44]--[2018-03-05 Mon 15:16] =>  1:32
     CLOCK: [2018-03-05 Mon 10:50]--[2018-03-05 Mon 12:00] =>  1:10

- Python3 应用的缓存 -> pip 的缓存机制

缓存机制好像没有生效，但是构建速度非常快。
现在都是用 wheel，从 HDFS 或者 pypi 上拉，已经差不多了。

**** TODO oauth-LDAP posixAccount
**** TODO oauth 修改密码，不能重复
**** DONE 支持 HDFS [4/4]                                              :work:
***** DONE CI 传输 s3 URL
     CLOCK: [2017-12-05 Tue 15:45]--[2017-12-05 Tue 17:59] =>  2:14
     CLOCK: [2017-12-05 Tue 10:49]--[2017-12-05 Tue 15:33] =>  4:44
     CLOCK: [2017-12-04 Mon 14:12]--[2017-12-04 Mon 15:00] =>  0:48

***** DONE 研究容器 DNS 解析失败的问题
     CLOCK: [2017-12-05 Tue 15:05]--[2017-12-05 Tue 20:05] =>  5:00
1. 控制变量法
2. route 的作用：route 是 IP 层面的东西；而 DNS 解析是 UDP 层面的东西。
   - IP 是网络层：看 route
   - TCP/UDP 是传输层：dns 解析等
3. netstat 的一个应用
   =udp    0      0 0.0.0.0:53    0.0.0.0:*   1434/dnsmasq=
   好像没啥好说的

***** DONE 开发生产环境均可以访问 HDFS
     CLOCK: [2017-12-06 Wed 14:00]--[2017-12-06 Wed 18:02] =>  4:02
1. HTTP status code: 307 vs 303
307 接受 POST/PUT 等请求
303 会建议你转成 GET 请求

2. Nginx 可以自动转发 307 请求吗？
   可以，一种方案：https://serverfault.com/a/792035

3. nginx 可以配置 standby upstream 吗？

***** DONE 部署系统兼容 HDFS 方案
     CLOCK: [2017-12-06 Wed 18:05]--[2017-12-06 Wed 19:23] =>  1:18

嗅觉：一个函数太长，应该有问题；引入的依赖太多或者太大，应该是有问题的。大概是这样吧...3

1. 放在 model 下，要嵌套两层概念：
artifact/storage: aws, hdfs
artifact/type: static, tarball

2. HDFS/AWS 保持相同的方法


[[https:https://mdn.mozillademos.org/files/13785/HTTPRedirect.png][redirect 流程图]]
**** 超级碎碎念
***** 资源收费
谷歌云提供按秒计算的能力。另外，在它的价格文档里面，它会告诉用户一台虚拟机
一个小时要收多少钱。

***** Oauth2 创建账号 + lens 问题
      CLOCK: [2018-03-12 Mon 14:50]--[2018-03-12 Mon 15:33] =>  0:43
https://xxx.slack.com/archives/D5EK0EQTX/p1520836061000112
**** DONE redis 迁移
     CLOCK: [2018-03-14 Thu 15:57]--[2018-03-15 Thu 16:57] => 25:00
线上不推荐用多 db
**** TODO 迁移 Oauth2 到 Python 3
     CLOCK: [2018-03-19 Mon 11:52]--[2018-03-19 Mon 16:00] =>  4:08
1. 加上 tox 工具
   - tox 没办法识别 versions.cfg
   - 在 buildout 里面跑 tox 显得毫无意义
   - 在 tox 里面跑 buildout 呢？
